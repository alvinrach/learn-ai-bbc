{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc72c8d3-54bc-43ee-ab89-eabcb2d2d3cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc72c8d3-54bc-43ee-ab89-eabcb2d2d3cb",
    "outputId": "4501f353-14b0-449f-d77a-ebd67605bebe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alvinrach/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2025-08-21 21:29:19.703811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-21 21:29:19.716698: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-21 21:29:19.720771: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-21 21:29:19.731352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-21 21:29:20.447914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import contractions\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17454a85-2872-4d25-9f99-611fff1e96b6",
   "metadata": {
    "id": "17454a85-2872-4d25-9f99-611fff1e96b6"
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('https://raw.githubusercontent.com/alvinrach/learn-ai-bbc/main/BBC%20News%20Train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/alvinrach/learn-ai-bbc/main/BBC%20News%20Test.csv')\n",
    "sample = pd.read_csv('https://raw.githubusercontent.com/alvinrach/learn-ai-bbc/main/BBC%20News%20Sample%20Solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d695b6d-bf5f-45fd-87ec-b6b0e7e84fe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d695b6d-bf5f-45fd-87ec-b6b0e7e84fe4",
    "outputId": "a85bfec2-8ad4-483d-b50c-5bf687fe3fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.1+ KB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89069743-0f54-47ad-8c9d-5d68adf3e7b0",
   "metadata": {
    "id": "89069743-0f54-47ad-8c9d-5d68adf3e7b0"
   },
   "outputs": [],
   "source": [
    "d = d.drop('ArticleId',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2cb443-e83f-4d82-97fc-3ab8adc808e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "8a2cb443-e83f-4d82-97fc-3ab8adc808e0",
    "outputId": "ff195e57-a1d5-4210-e799-7cdb17da45fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>double eviction from big brother model caprice...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>apple ipod family expands market apple has exp...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text       Category\n",
       "0     worldcom ex-boss launches defence lawyers defe...       business\n",
       "1     german business confidence slides german busin...       business\n",
       "2     bbc poll indicates economic gloom citizens in ...       business\n",
       "3     lifestyle  governs mobile choice  faster  bett...           tech\n",
       "4     enron bosses in $168m payout eighteen former e...       business\n",
       "...                                                 ...            ...\n",
       "1485  double eviction from big brother model caprice...  entertainment\n",
       "1486  dj double act revamp chart show dj duo jk and ...  entertainment\n",
       "1487  weak dollar hits reuters revenues at media gro...       business\n",
       "1488  apple ipod family expands market apple has exp...           tech\n",
       "1489  santy worm makes unwelcome visit thousands of ...           tech\n",
       "\n",
       "[1490 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f32074-eb39-4522-9966-edb87c6f5c0b",
   "metadata": {
    "id": "b9f32074-eb39-4522-9966-edb87c6f5c0b"
   },
   "outputs": [],
   "source": [
    "def txtprocess(txt):\n",
    "    txt = str(txt).lower()\n",
    "    txt = contractions.fix(txt)\n",
    "\n",
    "    txt = re.sub(r'[^a-zA-Z]', ' ', txt)\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "\n",
    "    txt = ' '.join(txt.split())\n",
    "\n",
    "    return txt\n",
    "\n",
    "d['Text'] = d['Text'].apply(txtprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb78483-02de-40b4-b7e9-0b79e6d805a6",
   "metadata": {
    "id": "ddb78483-02de-40b4-b7e9-0b79e6d805a6"
   },
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# kayak you'll gitu masih ada ' nya , apa bagusnya sebelum txtprocess, tapi kecil semua sih\n",
    "def remove_stopwords(txt):\n",
    "    no_stopword_txt = [w for w in txt.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_txt)\n",
    "\n",
    "d['Text'] = d['Text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e665ba-b138-4bb7-9381-716d59471de0",
   "metadata": {
    "id": "41e665ba-b138-4bb7-9381-716d59471de0"
   },
   "outputs": [],
   "source": [
    "# Alternative but just not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf105bf-53e2-4073-ae6a-2d46ead5bda0",
   "metadata": {
    "id": "4cf105bf-53e2-4073-ae6a-2d46ead5bda0"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(txt):\n",
    "    no_stopword_txt = [w for w in txt.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_txt)\n",
    "\n",
    "def txtprocess(txt):\n",
    "    txt = str(txt).lower()\n",
    "    txt = contractions.fix(txt)\n",
    "    txt = remove_stopwords(txt)\n",
    "\n",
    "    txt = re.sub(r'[^a-zA-Z]', ' ', txt)\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "\n",
    "    txt = ' '.join(txt.split())\n",
    "\n",
    "    return txt\n",
    "\n",
    "d['Text'] = d['Text'].apply(txtprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d58444-c276-4a4f-a5c2-2c081186f5a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "e1d58444-c276-4a4f-a5c2-2c081186f5a3",
    "outputId": "7151c955-c80c-4a42-aeda-eaebef594bd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>business</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>tech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex boss launches defence lawyers defe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens maj...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses payout eighteen former enron dire...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>double eviction big brother model caprice holb...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>dj double act revamp chart show dj duo jk joel...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>weak dollar hits reuters revenues media group ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>apple ipod family expands market apple expande...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>santy worm makes unwelcome visit thousands web...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  business  \\\n",
       "0     worldcom ex boss launches defence lawyers defe...         1   \n",
       "1     german business confidence slides german busin...         1   \n",
       "2     bbc poll indicates economic gloom citizens maj...         1   \n",
       "3     lifestyle governs mobile choice faster better ...         0   \n",
       "4     enron bosses payout eighteen former enron dire...         1   \n",
       "...                                                 ...       ...   \n",
       "1485  double eviction big brother model caprice holb...         0   \n",
       "1486  dj double act revamp chart show dj duo jk joel...         0   \n",
       "1487  weak dollar hits reuters revenues media group ...         1   \n",
       "1488  apple ipod family expands market apple expande...         0   \n",
       "1489  santy worm makes unwelcome visit thousands web...         0   \n",
       "\n",
       "      entertainment  politics  sport  tech  \n",
       "0                 0         0      0     0  \n",
       "1                 0         0      0     0  \n",
       "2                 0         0      0     0  \n",
       "3                 0         0      0     1  \n",
       "4                 0         0      0     0  \n",
       "...             ...       ...    ...   ...  \n",
       "1485              1         0      0     0  \n",
       "1486              1         0      0     0  \n",
       "1487              0         0      0     0  \n",
       "1488              0         0      0     1  \n",
       "1489              0         0      0     1  \n",
       "\n",
       "[1490 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = pd.get_dummies(d.Category, dtype=int)\n",
    "d_new = pd.concat([d, category], axis=1)\n",
    "d_new = d_new.drop('Category', axis=1)\n",
    "d_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c97eb5eb-e5e2-4375-9a6d-bdde8319e0e5",
   "metadata": {
    "id": "c97eb5eb-e5e2-4375-9a6d-bdde8319e0e5"
   },
   "outputs": [],
   "source": [
    "article = d_new['Text'].values\n",
    "label = d_new[category.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vgRqXiRQpzNc",
   "metadata": {
    "id": "vgRqXiRQpzNc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvinrach/.jupytervenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize directly (no fit_on_texts needed - it's already pretrained!)\n",
    "tokens = tokenizer(article.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Split the tokenized data\n",
    "padded_train, padded_test, y_train, y_test = train_test_split(\n",
    "    tokens['input_ids'], label, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "NlkNE6-oqd6L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlkNE6-oqd6L",
    "outputId": "48210909-607d-4ab7-9129-a7c024175957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101, 11865,  6562,  ...,     0,     0,     0],\n",
       "         [  101,  4121,  5481,  ...,     0,     0,     0],\n",
       "         [  101,  7206,  3404,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 23413,  2229,  ...,     0,     0,     0],\n",
       "         [  101,  3153,  2189,  ...,     0,     0,     0],\n",
       "         [  101,  3306,  3940,  ...,     0,     0,     0]]),\n",
       " array([[0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "SrT8zuZYsVdV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrT8zuZYsVdV",
    "outputId": "1ec866c4-70a7-490b-e406-d1d54fc4144b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VuRJB9YRwGW",
   "metadata": {
    "id": "9VuRJB9YRwGW"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=tokenizer.vocab_size+1, output_dim=500, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vmx8pOhfVvaF",
   "metadata": {
    "id": "vmx8pOhfVvaF"
   },
   "outputs": [],
   "source": [
    "# Purist, kureng. masih bingung sebenarnya padding_idx=1 itu masked apa engga\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=500, hidden_dim=64, output_dim=5):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embedding_dim, padding_idx=1)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "        output, (h_n, c_n) = self.lstm(x)  # output: [batch_size, seq_len, hidden_dim]\n",
    "        x = h_n[-1]  # take the last hidden state\n",
    "        x = self.fc(x)  # [batch_size, output_dim]\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MyModel(vocab_size)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # same as categorical_crossentropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485cd44-fb61-4643-82b3-70cd73d9f854",
   "metadata": {
    "id": "b485cd44-fb61-4643-82b3-70cd73d9f854"
   },
   "outputs": [],
   "source": [
    "# dengan pad packed sequence, tp padding_idx 0\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=500, hidden_dim=64, output_dim=5):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # compute lengths of non-padded tokens\n",
    "        lengths = torch.sum(x.abs().sum(dim=2) != 0, dim=1)  # or use original input: x_input != 0\n",
    "        # pack the sequence\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # pass through LSTM\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed)\n",
    "        # unpack if needed (not necessary if just taking last hidden)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # take last hidden state for classification\n",
    "        x = h_n[-1]  # [batch_size, hidden_dim]\n",
    "        x = self.fc(x)  # [batch_size, output_dim]\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MyModel(vocab_size)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # same as categorical_crossentropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "JLPryePIZFP4",
   "metadata": {
    "id": "JLPryePIZFP4"
   },
   "outputs": [],
   "source": [
    "# katanya sih biar mimic keras kita harus mimic weight nya keras dan pake forget gate bias nya keras\n",
    "# ini yang terbaik\n",
    "# Epoch 46/60, Train Loss: 0.9059, Val Loss: 0.9397, Val Acc: 0.9698\n",
    "# Epoch 47/60, Train Loss: 0.9059, Val Loss: 0.9399, Val Acc: 0.9732\n",
    "# Epoch 48/60, Train Loss: 0.9059, Val Loss: 0.9408, Val Acc: 0.9664\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=500, hidden_dim=64, output_dim=5):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # compute lengths of non-padded tokens\n",
    "        lengths = torch.sum(x.abs().sum(dim=2) != 0, dim=1)  # or use original input: x_input != 0\n",
    "        # pack the sequence\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # pass through LSTM\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed)\n",
    "        # unpack if needed (not necessary if just taking last hidden)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # take last hidden state for classification\n",
    "        x = h_n[-1]  # [batch_size, hidden_dim]\n",
    "        x = self.fc(x)  # [batch_size, output_dim]\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MyModel(vocab_size)\n",
    "\n",
    "# 4) Weight initialization to mimic Keras\n",
    "def init_lstm_like_keras(m):\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        # Keras embed init is usually uniform small; this is OK\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "        if m.padding_idx is not None:\n",
    "            with torch.no_grad():\n",
    "                m.weight[m.padding_idx].fill_(0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)   # kernel ~ glorot\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)       # recurrent ~ orthogonal\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param.data)\n",
    "\n",
    "model.apply(init_lstm_like_keras)\n",
    "\n",
    "# 5) Set forget-gate bias = 1 (handles bias_ih + bias_hh)\n",
    "for names in model.lstm._all_weights:\n",
    "    for name in names:\n",
    "        if 'bias' in name:\n",
    "            bias = getattr(model.lstm, name)\n",
    "            n = bias.size(0)\n",
    "            # gates are i, f, g, o => forget gate slice is n//4 to n//4*2\n",
    "            start = n // 4\n",
    "            end = start + n // 4\n",
    "            with torch.no_grad():\n",
    "                bias[start:end].fill_(1.0)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # same as categorical_crossentropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Aw7ysxWQZ4hs",
   "metadata": {
    "id": "Aw7ysxWQZ4hs"
   },
   "outputs": [],
   "source": [
    "# sebenarnya perlu ga sih pad packed sequence\n",
    "# ternyata malah makin jelek. jadi exp ke 3 diambil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=500, hidden_dim=64, output_dim=5):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embedding_dim, padding_idx=1)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "        output, (h_n, c_n) = self.lstm(x)  # output: [batch_size, seq_len, hidden_dim]\n",
    "        x = h_n[-1]  # take the last hidden state\n",
    "        x = self.fc(x)  # [batch_size, output_dim]\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MyModel(vocab_size)\n",
    "\n",
    "# 4) Weight initialization to mimic Keras\n",
    "def init_lstm_like_keras(m):\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        # Keras embed init is usually uniform small; this is OK\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "        if m.padding_idx is not None:\n",
    "            with torch.no_grad():\n",
    "                m.weight[m.padding_idx].fill_(0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)   # kernel ~ glorot\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)       # recurrent ~ orthogonal\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param.data)\n",
    "\n",
    "model.apply(init_lstm_like_keras)\n",
    "\n",
    "# 5) Set forget-gate bias = 1 (handles bias_ih + bias_hh)\n",
    "for names in model.lstm._all_weights:\n",
    "    for name in names:\n",
    "        if 'bias' in name:\n",
    "            bias = getattr(model.lstm, name)\n",
    "            n = bias.size(0)\n",
    "            # gates are i, f, g, o => forget gate slice is n//4 to n//4*2\n",
    "            start = n // 4\n",
    "            end = start + n // 4\n",
    "            with torch.no_grad():\n",
    "                bias[start:end].fill_(1.0)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # same as categorical_crossentropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "CmQmJ74wuGWQ",
   "metadata": {
    "id": "CmQmJ74wuGWQ"
   },
   "outputs": [],
   "source": [
    "# katanya sih biar mimic keras kita harus mimic weight nya keras dan pake forget gate bias nya keras\n",
    "# ini yang terbaik\n",
    "# Tapi apakah karena weight?\n",
    "# Epoch 59/60, Train Loss: 0.9058, Val Loss: 1.0580, Val Acc: 0.8389\n",
    "# Epoch 60/60, Train Loss: 0.9058, Val Loss: 1.0588, Val Acc: 0.8423\n",
    "# Good but stuck\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=500, hidden_dim=64, output_dim=5):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # compute lengths of non-padded tokens\n",
    "        lengths = torch.sum(x.abs().sum(dim=2) != 0, dim=1)  # or use original input: x_input != 0\n",
    "        # pack the sequence\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # pass through LSTM\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed)\n",
    "        # unpack if needed (not necessary if just taking last hidden)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # take last hidden state for classification\n",
    "        x = h_n[-1]  # [batch_size, hidden_dim]\n",
    "        x = self.fc(x)  # [batch_size, output_dim]\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MyModel(vocab_size)\n",
    "\n",
    "# 4) Weight initialization to mimic Keras\n",
    "def init_lstm_like_keras(m):\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        # Keras embed init is usually uniform small; this is OK\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "        if m.padding_idx is not None:\n",
    "            with torch.no_grad():\n",
    "                m.weight[m.padding_idx].fill_(0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)   # kernel ~ glorot\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)       # recurrent ~ orthogonal\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param.data)\n",
    "\n",
    "model.apply(init_lstm_like_keras)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # same as categorical_crossentropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "FN9QAax3uLnt",
   "metadata": {
    "id": "FN9QAax3uLnt"
   },
   "outputs": [],
   "source": [
    "# katanya sih biar mimic keras kita harus mimic weight nya keras dan pake forget gate bias nya keras\n",
    "# ini yang terbaik\n",
    "# Atau karena forget gate bias aja?\n",
    "# Epoch 49/60, Train Loss: 0.9062, Val Loss: 0.9934, Val Acc: 0.9128\n",
    "# Epoch 50/60, Train Loss: 0.9062, Val Loss: 0.9933, Val Acc: 0.9128\n",
    "# Epoch 51/60, Train Loss: 0.9061, Val Loss: 0.9933, Val Acc: 0.9094\n",
    "# Epoch 52/60, Train Loss: 0.9061, Val Loss: 0.9936, Val Acc: 0.9094\n",
    "# Mmg mostly karena forget gate bias. Tapi dia ga sampe 97% kek yg exp ketiga\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=500, hidden_dim=64, output_dim=5):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # compute lengths of non-padded tokens\n",
    "        lengths = torch.sum(x.abs().sum(dim=2) != 0, dim=1)  # or use original input: x_input != 0\n",
    "        # pack the sequence\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # pass through LSTM\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed)\n",
    "        # unpack if needed (not necessary if just taking last hidden)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # take last hidden state for classification\n",
    "        x = h_n[-1]  # [batch_size, hidden_dim]\n",
    "        x = self.fc(x)  # [batch_size, output_dim]\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MyModel(vocab_size)\n",
    "\n",
    "# 5) Set forget-gate bias = 1 (handles bias_ih + bias_hh)\n",
    "for names in model.lstm._all_weights:\n",
    "    for name in names:\n",
    "        if 'bias' in name:\n",
    "            bias = getattr(model.lstm, name)\n",
    "            n = bias.size(0)\n",
    "            # gates are i, f, g, o => forget gate slice is n//4 to n//4*2\n",
    "            start = n // 4\n",
    "            end = start + n // 4\n",
    "            with torch.no_grad():\n",
    "                bias[start:end].fill_(1.0)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # same as categorical_crossentropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebe809-b7ed-4d6e-aee0-dd95c3352d35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "d4ebe809-b7ed-4d6e-aee0-dd95c3352d35",
    "outputId": "0c918105-16eb-476f-eabd-c7be667ceb30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3726492126.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(padded_train, dtype=torch.long)\n",
      "/tmp/ipython-input-3726492126.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(padded_test, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 1.6067, Val Loss: 1.6081, Val Acc: 0.2181\n",
      "Epoch 2/60, Train Loss: 1.6019, Val Loss: 1.6062, Val Acc: 0.2181\n",
      "Epoch 3/60, Train Loss: 1.5980, Val Loss: 1.6046, Val Acc: 0.2181\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3726492126.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cpu\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Convert your data to PyTorch tensors\n",
    "X_train_tensor = padded_train.clone().detach().long()\n",
    "y_train_tensor = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)  # if one-hot\n",
    "X_val_tensor = padded_test.clone().detach().long()\n",
    "y_val_tensor = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 15\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            correct += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        best_model_state = model.state_dict()  # save best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            model.load_state_dict(best_model_state)  # restore best model\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30lezpB2S9Dz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30lezpB2S9Dz",
    "outputId": "bb3e6e4f-12f0-4ad7-b7cd-96d6f92af88d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6681/35588772.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(padded_train, dtype=torch.long)\n",
      "/tmp/ipykernel_6681/35588772.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(padded_test, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 1.6056, Val Loss: 1.5985, Val Acc: 0.2617\n",
      "Epoch 2/60, Train Loss: 1.5993, Val Loss: 1.5976, Val Acc: 0.2617\n",
      "Epoch 3/60, Train Loss: 1.5972, Val Loss: 1.6010, Val Acc: 0.2181\n",
      "Epoch 4/60, Train Loss: 1.5949, Val Loss: 1.6023, Val Acc: 0.2181\n",
      "Epoch 5/60, Train Loss: 1.5927, Val Loss: 1.6013, Val Acc: 0.2181\n",
      "Epoch 6/60, Train Loss: 1.5901, Val Loss: 1.6016, Val Acc: 0.2148\n",
      "Epoch 7/60, Train Loss: 1.5879, Val Loss: 1.6007, Val Acc: 0.2148\n",
      "Epoch 8/60, Train Loss: 1.5864, Val Loss: 1.6001, Val Acc: 0.2148\n",
      "Epoch 9/60, Train Loss: 1.5849, Val Loss: 1.6021, Val Acc: 0.2148\n",
      "Epoch 10/60, Train Loss: 1.5835, Val Loss: 1.6010, Val Acc: 0.2148\n",
      "Epoch 11/60, Train Loss: 1.5824, Val Loss: 1.6010, Val Acc: 0.2148\n",
      "Epoch 12/60, Train Loss: 1.5818, Val Loss: 1.6007, Val Acc: 0.2148\n",
      "Epoch 13/60, Train Loss: 1.5818, Val Loss: 1.5992, Val Acc: 0.2248\n",
      "Epoch 14/60, Train Loss: 1.5815, Val Loss: 1.5988, Val Acc: 0.2685\n",
      "Epoch 15/60, Train Loss: 1.5791, Val Loss: 1.5988, Val Acc: 0.2852\n",
      "Epoch 16/60, Train Loss: 1.5768, Val Loss: 1.5975, Val Acc: 0.3121\n",
      "Epoch 17/60, Train Loss: 1.5732, Val Loss: 1.5947, Val Acc: 0.3322\n",
      "Epoch 18/60, Train Loss: 1.5678, Val Loss: 1.5918, Val Acc: 0.3322\n",
      "Epoch 19/60, Train Loss: 1.5604, Val Loss: 1.5882, Val Acc: 0.2651\n",
      "Epoch 20/60, Train Loss: 1.5497, Val Loss: 1.5798, Val Acc: 0.3624\n",
      "Epoch 21/60, Train Loss: 1.5345, Val Loss: 1.5495, Val Acc: 0.3893\n",
      "Epoch 22/60, Train Loss: 1.4858, Val Loss: 1.5353, Val Acc: 0.3993\n",
      "Epoch 23/60, Train Loss: 1.4774, Val Loss: 1.5387, Val Acc: 0.3826\n",
      "Epoch 24/60, Train Loss: 1.4806, Val Loss: 1.5538, Val Acc: 0.2148\n",
      "Epoch 25/60, Train Loss: 1.4901, Val Loss: 1.5406, Val Acc: 0.3792\n",
      "Epoch 26/60, Train Loss: 1.4741, Val Loss: 1.5335, Val Acc: 0.3792\n",
      "Epoch 27/60, Train Loss: 1.4587, Val Loss: 1.5185, Val Acc: 0.3859\n",
      "Epoch 28/60, Train Loss: 1.4425, Val Loss: 1.5041, Val Acc: 0.3926\n",
      "Epoch 29/60, Train Loss: 1.4254, Val Loss: 1.4902, Val Acc: 0.3993\n",
      "Epoch 30/60, Train Loss: 1.4086, Val Loss: 1.4839, Val Acc: 0.3960\n",
      "Epoch 31/60, Train Loss: 1.3958, Val Loss: 1.4773, Val Acc: 0.3993\n",
      "Epoch 32/60, Train Loss: 1.3835, Val Loss: 1.4738, Val Acc: 0.3893\n",
      "Epoch 33/60, Train Loss: 1.3696, Val Loss: 1.4675, Val Acc: 0.3993\n",
      "Epoch 34/60, Train Loss: 1.3567, Val Loss: 1.4548, Val Acc: 0.4631\n",
      "Epoch 35/60, Train Loss: 1.3416, Val Loss: 1.4651, Val Acc: 0.4799\n",
      "Epoch 36/60, Train Loss: 1.3351, Val Loss: 1.4730, Val Acc: 0.4564\n",
      "Epoch 37/60, Train Loss: 1.4317, Val Loss: 1.4972, Val Acc: 0.5671\n",
      "Epoch 38/60, Train Loss: 1.3974, Val Loss: 1.4597, Val Acc: 0.5168\n",
      "Epoch 39/60, Train Loss: 1.3663, Val Loss: 1.4857, Val Acc: 0.4765\n",
      "Epoch 40/60, Train Loss: 1.4049, Val Loss: 1.4734, Val Acc: 0.5134\n",
      "Epoch 41/60, Train Loss: 1.3792, Val Loss: 1.4547, Val Acc: 0.5671\n",
      "Epoch 42/60, Train Loss: 1.3546, Val Loss: 1.4430, Val Acc: 0.5268\n",
      "Epoch 43/60, Train Loss: 1.3361, Val Loss: 1.4292, Val Acc: 0.5705\n",
      "Epoch 44/60, Train Loss: 1.3166, Val Loss: 1.4187, Val Acc: 0.5839\n",
      "Epoch 45/60, Train Loss: 1.2931, Val Loss: 1.4130, Val Acc: 0.5604\n",
      "Epoch 46/60, Train Loss: 1.2707, Val Loss: 1.4094, Val Acc: 0.5705\n",
      "Epoch 47/60, Train Loss: 1.2487, Val Loss: 1.4054, Val Acc: 0.5638\n",
      "Epoch 48/60, Train Loss: 1.2189, Val Loss: 1.3958, Val Acc: 0.6141\n",
      "Epoch 49/60, Train Loss: 1.1992, Val Loss: 1.3858, Val Acc: 0.6141\n",
      "Epoch 50/60, Train Loss: 1.1702, Val Loss: 1.3702, Val Acc: 0.6141\n",
      "Epoch 51/60, Train Loss: 1.1496, Val Loss: 1.3580, Val Acc: 0.6309\n",
      "Epoch 52/60, Train Loss: 1.1223, Val Loss: 1.3473, Val Acc: 0.6107\n",
      "Epoch 53/60, Train Loss: 1.1019, Val Loss: 1.3324, Val Acc: 0.6477\n",
      "Epoch 54/60, Train Loss: 1.0857, Val Loss: 1.3206, Val Acc: 0.6577\n",
      "Epoch 55/60, Train Loss: 1.0682, Val Loss: 1.3183, Val Acc: 0.6577\n",
      "Epoch 56/60, Train Loss: 1.0508, Val Loss: 1.3162, Val Acc: 0.6577\n",
      "Epoch 57/60, Train Loss: 1.0331, Val Loss: 1.3046, Val Acc: 0.6544\n",
      "Epoch 58/60, Train Loss: 1.0194, Val Loss: 1.3073, Val Acc: 0.6577\n",
      "Epoch 59/60, Train Loss: 1.0085, Val Loss: 1.2913, Val Acc: 0.6779\n",
      "Epoch 60/60, Train Loss: 0.9977, Val Loss: 1.2796, Val Acc: 0.6812\n"
     ]
    }
   ],
   "source": [
    "#gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Convert your data to PyTorch tensors\n",
    "X_train_tensor = padded_train.clone().detach().long()\n",
    "y_train_tensor = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)  # if one-hot\n",
    "X_val_tensor = padded_test.clone().detach().long()\n",
    "y_val_tensor = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 15\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            correct += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        best_model_state = model.state_dict()  # save best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            model.load_state_dict(best_model_state)  # restore best model\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70776e53-e4fa-465b-9083-4f5219c70d74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70776e53-e4fa-465b-9083-4f5219c70d74",
    "outputId": "dd8ad05b-c943-4dc2-81d5-0dfbd0849062",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "10/10 - 9s - 869ms/step - accuracy: 0.2718 - loss: 1.5916 - val_accuracy: 0.3221 - val_loss: 1.5562\n",
      "Epoch 2/60\n",
      "10/10 - 0s - 46ms/step - accuracy: 0.6611 - loss: 1.3697 - val_accuracy: 0.5906 - val_loss: 1.1325\n",
      "Epoch 3/60\n",
      "10/10 - 0s - 47ms/step - accuracy: 0.9111 - loss: 0.7094 - val_accuracy: 0.8389 - val_loss: 0.6645\n",
      "Epoch 4/60\n",
      "10/10 - 1s - 62ms/step - accuracy: 0.9874 - loss: 0.2542 - val_accuracy: 0.9262 - val_loss: 0.3035\n",
      "Epoch 5/60\n",
      "10/10 - 0s - 46ms/step - accuracy: 0.9975 - loss: 0.0524 - val_accuracy: 0.9329 - val_loss: 0.2563\n",
      "Epoch 6/60\n",
      "10/10 - 1s - 50ms/step - accuracy: 0.9983 - loss: 0.0177 - val_accuracy: 0.9396 - val_loss: 0.2441\n",
      "Epoch 7/60\n",
      "10/10 - 1s - 53ms/step - accuracy: 0.9992 - loss: 0.0094 - val_accuracy: 0.9362 - val_loss: 0.2699\n",
      "Epoch 8/60\n",
      "10/10 - 1s - 64ms/step - accuracy: 0.9992 - loss: 0.0088 - val_accuracy: 0.9295 - val_loss: 0.3358\n",
      "Epoch 9/60\n",
      "10/10 - 1s - 60ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9161 - val_loss: 0.3769\n",
      "Epoch 10/60\n",
      "10/10 - 0s - 46ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9161 - val_loss: 0.3839\n",
      "Epoch 11/60\n",
      "10/10 - 0s - 46ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9228 - val_loss: 0.3800\n",
      "Epoch 12/60\n",
      "10/10 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9228 - val_loss: 0.3779\n",
      "Epoch 13/60\n",
      "10/10 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9228 - val_loss: 0.3774\n",
      "Epoch 14/60\n",
      "10/10 - 0s - 48ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9228 - val_loss: 0.3736\n",
      "Epoch 15/60\n",
      "10/10 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9228 - val_loss: 0.3692\n",
      "Epoch 16/60\n",
      "10/10 - 0s - 47ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9228 - val_loss: 0.3748\n",
      "Epoch 17/60\n",
      "10/10 - 0s - 48ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9228 - val_loss: 0.3811\n",
      "Epoch 18/60\n",
      "10/10 - 0s - 47ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9228 - val_loss: 0.3842\n",
      "Epoch 19/60\n",
      "10/10 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9295 - val_loss: 0.3852\n",
      "Epoch 20/60\n",
      "10/10 - 0s - 46ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9295 - val_loss: 0.3906\n",
      "Epoch 21/60\n",
      "10/10 - 0s - 47ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9295 - val_loss: 0.3958\n"
     ]
    }
   ],
   "source": [
    "set_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "history = model.fit(padded_train, y_train, epochs=60, batch_size=128,\n",
    "                   validation_data=(padded_test, y_test), callbacks=[set_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uuq3ZyHnGolz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuq3ZyHnGolz",
    "outputId": "e74553ed-b9b3-49d8-abdf-39a1386b1308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9234 - loss: 0.3850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39577338099479675, 0.9295302033424377]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padded_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-7ncbMISGwja",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7ncbMISGwja",
    "outputId": "e172775d-6327-4796-f914-12f790b912e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "12/12 - 4s - 361ms/step - accuracy: 0.2315 - loss: 1.6064\n",
      "Epoch 2/60\n",
      "12/12 - 2s - 135ms/step - accuracy: 0.3107 - loss: 1.5851\n",
      "Epoch 3/60\n",
      "12/12 - 0s - 37ms/step - accuracy: 0.4054 - loss: 1.5488\n",
      "Epoch 4/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.5094 - loss: 1.4383\n",
      "Epoch 5/60\n",
      "12/12 - 0s - 37ms/step - accuracy: 0.5174 - loss: 1.1650\n",
      "Epoch 6/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.5591 - loss: 0.9750\n",
      "Epoch 7/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.7584 - loss: 0.8106\n",
      "Epoch 8/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.8517 - loss: 0.6544\n",
      "Epoch 9/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9081 - loss: 0.5152\n",
      "Epoch 10/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9430 - loss: 0.3807\n",
      "Epoch 11/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9658 - loss: 0.2818\n",
      "Epoch 12/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9732 - loss: 0.2333\n",
      "Epoch 13/60\n",
      "12/12 - 0s - 37ms/step - accuracy: 0.9839 - loss: 0.1710\n",
      "Epoch 14/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9839 - loss: 0.1545\n",
      "Epoch 15/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9812 - loss: 0.1334\n",
      "Epoch 16/60\n",
      "12/12 - 1s - 53ms/step - accuracy: 0.9819 - loss: 0.1214\n",
      "Epoch 17/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9872 - loss: 0.1102\n",
      "Epoch 18/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9899 - loss: 0.0874\n",
      "Epoch 19/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9953 - loss: 0.0712\n",
      "Epoch 20/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9926 - loss: 0.0665\n",
      "Epoch 21/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9926 - loss: 0.0696\n",
      "Epoch 22/60\n",
      "12/12 - 1s - 57ms/step - accuracy: 0.9933 - loss: 0.0632\n",
      "Epoch 23/60\n",
      "12/12 - 1s - 50ms/step - accuracy: 0.9933 - loss: 0.0541\n",
      "Epoch 24/60\n",
      "12/12 - 1s - 46ms/step - accuracy: 0.9913 - loss: 0.0552\n",
      "Epoch 25/60\n",
      "12/12 - 1s - 48ms/step - accuracy: 0.9913 - loss: 0.0582\n",
      "Epoch 26/60\n",
      "12/12 - 1s - 49ms/step - accuracy: 0.9906 - loss: 0.0560\n",
      "Epoch 27/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9946 - loss: 0.0456\n",
      "Epoch 28/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9933 - loss: 0.0401\n",
      "Epoch 29/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9966 - loss: 0.0367\n",
      "Epoch 30/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9973 - loss: 0.0312\n",
      "Epoch 31/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9960 - loss: 0.0324\n",
      "Epoch 32/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9933 - loss: 0.0374\n",
      "Epoch 33/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9987 - loss: 0.0257\n",
      "Epoch 34/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9973 - loss: 0.0277\n",
      "Epoch 35/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9926 - loss: 0.0360\n",
      "Epoch 36/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9953 - loss: 0.0287\n",
      "Epoch 37/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9987 - loss: 0.0219\n",
      "Epoch 38/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9993 - loss: 0.0177\n",
      "Epoch 39/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9966 - loss: 0.0241\n",
      "Epoch 40/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9987 - loss: 0.0180\n",
      "Epoch 41/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9960 - loss: 0.0233\n",
      "Epoch 42/60\n",
      "12/12 - 1s - 51ms/step - accuracy: 0.9966 - loss: 0.0230\n",
      "Epoch 43/60\n",
      "12/12 - 1s - 58ms/step - accuracy: 0.9966 - loss: 0.0208\n",
      "Epoch 44/60\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9987 - loss: 0.0158\n",
      "Epoch 45/60\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9973 - loss: 0.0197\n",
      "Epoch 46/60\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9973 - loss: 0.0174\n",
      "Epoch 47/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9973 - loss: 0.0199\n",
      "Epoch 48/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9940 - loss: 0.0280\n",
      "Epoch 49/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9933 - loss: 0.0285\n",
      "Epoch 50/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9993 - loss: 0.0132\n",
      "Epoch 51/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9953 - loss: 0.0308\n",
      "Epoch 52/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 53/60\n",
      "12/12 - 1s - 52ms/step - accuracy: 0.9973 - loss: 0.0198\n",
      "Epoch 54/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9973 - loss: 0.0186\n",
      "Epoch 55/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 56/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.0093\n",
      "Epoch 57/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9987 - loss: 0.0109\n",
      "Epoch 58/60\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9966 - loss: 0.0180\n",
      "Epoch 59/60\n",
      "12/12 - 1s - 50ms/step - accuracy: 0.9980 - loss: 0.0133\n",
      "Epoch 60/60\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9960 - loss: 0.0188\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=tokenizer.vocab_size+1, output_dim=500, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(16, dropout=0.9),\n",
    "    tf.keras.layers.Dense(5,activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "X_all = np.concatenate((padded_train, padded_test))\n",
    "y_all = np.concatenate((y_train, y_test))\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<=history.history['loss'][-1]):\n",
    "            print('Stopped, reach same losses as splitted trial')\n",
    "            self.model.stop_training = True\n",
    "set_callback = myCallback()\n",
    "\n",
    "history = model.fit(X_all, y_all, epochs=60, batch_size=128,\n",
    "                    callbacks=[set_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1sQv4T5EIWYz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1sQv4T5EIWYz",
    "outputId": "1df95717-d0c1-407b-a8e7-acf0a174d630"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"sample\",\n  \"rows\": 735,\n  \"fields\": [\n    {\n      \"column\": \"ArticleId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 643,\n        \"min\": 1,\n        \"max\": 2225,\n        \"num_unique_values\": 735,\n        \"samples\": [\n          1810,\n          1556,\n          1288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"tech\",\n          \"politics\",\n          \"business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "sample"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-78c5f22e-1822-4dd6-a9f4-2dce4e3e3eff\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1923</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>373</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1704</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>206</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>471</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78c5f22e-1822-4dd6-a9f4-2dce4e3e3eff')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-78c5f22e-1822-4dd6-a9f4-2dce4e3e3eff button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-78c5f22e-1822-4dd6-a9f4-2dce4e3e3eff');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-34e8c1f8-bd53-413f-9566-89146aafe732\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34e8c1f8-bd53-413f-9566-89146aafe732')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-34e8c1f8-bd53-413f-9566-89146aafe732 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_fa96d740-dbb0-472b-98db-553ef56cd0e5\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_fa96d740-dbb0-472b-98db-553ef56cd0e5 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('sample');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     ArticleId       Category\n",
       "0         1018          sport\n",
       "1         1319           tech\n",
       "2         1138       business\n",
       "3          459  entertainment\n",
       "4         1020       politics\n",
       "..         ...            ...\n",
       "730       1923          sport\n",
       "731        373           tech\n",
       "732       1704       business\n",
       "733        206  entertainment\n",
       "734        471       politics\n",
       "\n",
       "[735 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hUF58gNS7ikA",
   "metadata": {
    "id": "hUF58gNS7ikA"
   },
   "outputs": [],
   "source": [
    "test['Text'] = test['Text'].apply(txtprocess)\n",
    "test['Text'] = test['Text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "testtext = test['Text'].values\n",
    "\n",
    "paddedtesttext = tokenizer(testtext.tolist(), padding=True, truncation=True, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MKkEzRJKJu0r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "MKkEzRJKJu0r",
    "outputId": "8571fd5f-cd48-4dfe-faaf-81b212ffaaa6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"answer\",\n  \"rows\": 735,\n  \"fields\": [\n    {\n      \"column\": \"ArticleId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 643,\n        \"min\": 1,\n        \"max\": 2225,\n        \"num_unique_values\": 735,\n        \"samples\": [\n          1810,\n          1556,\n          1288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"tech\",\n          \"entertainment\",\n          \"business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "answer"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e2f6f6a1-e4c4-4b1b-a58b-174d028efc4a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1923</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>373</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1704</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>206</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>471</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2f6f6a1-e4c4-4b1b-a58b-174d028efc4a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e2f6f6a1-e4c4-4b1b-a58b-174d028efc4a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e2f6f6a1-e4c4-4b1b-a58b-174d028efc4a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-af2438f4-2a0b-475d-9169-286b9ea6729f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af2438f4-2a0b-475d-9169-286b9ea6729f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-af2438f4-2a0b-475d-9169-286b9ea6729f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_94d1c384-27cc-4818-89bd-be8f34655088\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('answer')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_94d1c384-27cc-4818-89bd-be8f34655088 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('answer');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     ArticleId       Category\n",
       "0         1018          sport\n",
       "1         1319           tech\n",
       "2         1138          sport\n",
       "3          459       business\n",
       "4         1020          sport\n",
       "..         ...            ...\n",
       "730       1923       politics\n",
       "731        373  entertainment\n",
       "732       1704       politics\n",
       "733        206       business\n",
       "734        471       politics\n",
       "\n",
       "[735 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3️⃣ Move model and data to device\n",
    "model.eval()  # important: set to evaluation mode\n",
    "paddedtesttext = paddedtesttext.to(device)\n",
    "\n",
    "# 4️⃣ Forward pass & get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(paddedtesttext)  # [batch_size, output_dim]\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()  # convert to numpy\n",
    "\n",
    "# 5️⃣ Map integer predictions to original category names\n",
    "mapping = dict(enumerate(category.columns))\n",
    "pred_labels = pd.Series(preds).map(mapping)\n",
    "\n",
    "# 6️⃣ Combine with ArticleId\n",
    "answer = pd.concat([test['ArticleId'].reset_index(drop=True), pred_labels.reset_index(drop=True)], axis=1)\n",
    "answer.columns = ['ArticleId', 'Category']\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_7LdVio_bJCz",
   "metadata": {
    "id": "_7LdVio_bJCz"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fd1ff-7ea0-4699-b109-82f3353331ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(paddedtesttext)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "all_preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (X_batch,) in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "# Map integer predictions to original category names\n",
    "mapping = dict(enumerate(category.columns))\n",
    "pred_labels = pd.Series(all_preds).map(mapping)\n",
    "\n",
    "# Combine with ArticleId\n",
    "answer = pd.concat([test['ArticleId'].reset_index(drop=True), pred_labels.reset_index(drop=True)], axis=1)\n",
    "answer.columns = ['ArticleId', 'Category']\n",
    "\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00809ec31072481cab1dfe3a2ff009e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07e22ad2edc6451587e0f0ed2ab5de6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b2fb43ec57245c6b086e4fea0f93eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d50a31d34a44f2a8e325072df92090d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d8d83a47baf4a18acb3535908ddcd1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3c93c03aeae4d19a134ebad1680b35e",
      "placeholder": "​",
      "style": "IPY_MODEL_07e22ad2edc6451587e0f0ed2ab5de6a",
      "value": " 466k/466k [00:00&lt;00:00, 2.18MB/s]"
     }
    },
    "1819e08260044d30910b06226b129385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2f1492dcf1544fb8a0e3a1312c48035",
       "IPY_MODEL_394087d24c96458aa0b640815201859c",
       "IPY_MODEL_fc1c7c5e8eb94780b2fb0b5ef3b1fc54"
      ],
      "layout": "IPY_MODEL_a754b8cfecdc4cd092d1e98f528cf8d7"
     }
    },
    "1ad6e7da42e44a4883fdce2490abdfd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cc6a868e97d45f4969c5fb56e94f10f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b0b211600a514595b9c3943c668c2263",
       "IPY_MODEL_7feb538013464c8192db868884acfb88",
       "IPY_MODEL_9510a5385eae418dbc691c6ba8915e03"
      ],
      "layout": "IPY_MODEL_48ac19f630ee4fc389e6ba8c95520cf0"
     }
    },
    "394087d24c96458aa0b640815201859c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_814bb26961f8440cb26d421d73359671",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9092b7c50ab646f180aeb478049613f5",
      "value": 231508
     }
    },
    "3de8523b93ad46e996147abf479fabe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3eb1d141cf914657a0042f2d86962f6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "407266c2c2684843a6ab17cc9c95867b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e50651257c894699b35fa188d9cefe43",
      "placeholder": "​",
      "style": "IPY_MODEL_f739c95ab31a4df8a35623f2e3a57a87",
      "value": "tokenizer.json: 100%"
     }
    },
    "41437c9f20af494b9b75f96bd2b040d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_407266c2c2684843a6ab17cc9c95867b",
       "IPY_MODEL_eb26690718764ef7847c7be6f1f4861d",
       "IPY_MODEL_0d8d83a47baf4a18acb3535908ddcd1e"
      ],
      "layout": "IPY_MODEL_6e6844649d39421bb5432ea7f649a2b9"
     }
    },
    "4647e16b296b4c0aafc59f2fb1519ea6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48ac19f630ee4fc389e6ba8c95520cf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54e0d53ae26a4c37b6da762af436791c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3eb1d141cf914657a0042f2d86962f6e",
      "placeholder": "​",
      "style": "IPY_MODEL_0d50a31d34a44f2a8e325072df92090d",
      "value": " 48.0/48.0 [00:00&lt;00:00, 1.06kB/s]"
     }
    },
    "5ff5a12a9d4e4dc6af2be837f575c208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed72f63da46a44358d8e87ab101638fd",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68761919aeba46aa81e249b73c7a7dc1",
      "value": 48
     }
    },
    "68761919aeba46aa81e249b73c7a7dc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "694f8feb92984e6fbcdddc6aff6bbc15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e6844649d39421bb5432ea7f649a2b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70a3f9fc38c74e9b843117cd901e8df5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79d28e7ab0cf4e4db15e6466624240ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f991a999b0e4ecfadeba979c2f6a5e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7feb538013464c8192db868884acfb88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4647e16b296b4c0aafc59f2fb1519ea6",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6afbf1f23ce4b23a3fa087f9b700fb2",
      "value": 570
     }
    },
    "814bb26961f8440cb26d421d73359671": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ae24a175f54d9080e2627025b39e9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9092b7c50ab646f180aeb478049613f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9510a5385eae418dbc691c6ba8915e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79d28e7ab0cf4e4db15e6466624240ad",
      "placeholder": "​",
      "style": "IPY_MODEL_b9873db060a0485a844b18a251dd967d",
      "value": " 570/570 [00:00&lt;00:00, 19.6kB/s]"
     }
    },
    "a3c93c03aeae4d19a134ebad1680b35e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a754b8cfecdc4cd092d1e98f528cf8d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b06fabb6884c4103a6148cee334161d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00809ec31072481cab1dfe3a2ff009e8",
      "placeholder": "​",
      "style": "IPY_MODEL_beb44e34f8024ac19fc9ed75400064bc",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "b0b211600a514595b9c3943c668c2263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_694f8feb92984e6fbcdddc6aff6bbc15",
      "placeholder": "​",
      "style": "IPY_MODEL_70a3f9fc38c74e9b843117cd901e8df5",
      "value": "config.json: 100%"
     }
    },
    "b7344120806143ab97c1d56c10bf37c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9873db060a0485a844b18a251dd967d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "beb44e34f8024ac19fc9ed75400064bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c57f836f8bdd4fcfa3e292244a121c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b06fabb6884c4103a6148cee334161d6",
       "IPY_MODEL_5ff5a12a9d4e4dc6af2be837f575c208",
       "IPY_MODEL_54e0d53ae26a4c37b6da762af436791c"
      ],
      "layout": "IPY_MODEL_87ae24a175f54d9080e2627025b39e9f"
     }
    },
    "e50651257c894699b35fa188d9cefe43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6afbf1f23ce4b23a3fa087f9b700fb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb26690718764ef7847c7be6f1f4861d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f991a999b0e4ecfadeba979c2f6a5e8",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7344120806143ab97c1d56c10bf37c8",
      "value": 466062
     }
    },
    "ed72f63da46a44358d8e87ab101638fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2f1492dcf1544fb8a0e3a1312c48035": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ad6e7da42e44a4883fdce2490abdfd1",
      "placeholder": "​",
      "style": "IPY_MODEL_0b2fb43ec57245c6b086e4fea0f93eb2",
      "value": "vocab.txt: 100%"
     }
    },
    "f739c95ab31a4df8a35623f2e3a57a87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa85c2ffd1e64977b3a7ccf5134624dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc1c7c5e8eb94780b2fb0b5ef3b1fc54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa85c2ffd1e64977b3a7ccf5134624dd",
      "placeholder": "​",
      "style": "IPY_MODEL_3de8523b93ad46e996147abf479fabe8",
      "value": " 232k/232k [00:00&lt;00:00, 6.74MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
